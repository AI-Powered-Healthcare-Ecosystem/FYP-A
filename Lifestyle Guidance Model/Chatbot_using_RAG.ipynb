{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zXYJ_un7MkoG"
   },
   "outputs": [],
   "source": [
    "!pip install pinecone transformers sentence-transformers -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X9gyubQvJS9O"
   },
   "outputs": [],
   "source": [
    "!pip install transformers sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "51MiekBpJ-dr"
   },
   "outputs": [],
   "source": [
    "!pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JoEThB_xY3WD"
   },
   "outputs": [],
   "source": [
    "!pip install pymupdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E2HXRIWCJ_w6"
   },
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_text_from_pdf(path):\n",
    "    doc = fitz.open(path)\n",
    "    text = \"\"\n",
    "    for i, page in enumerate(doc):\n",
    "        text += f\"\\n--- Page {i+1} ---\\n\"\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "text_output = extract_text_from_pdf(\"MIMS.pdf\")\n",
    "print(text_output[:2000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bGpQD-1qKehi"
   },
   "outputs": [],
   "source": [
    "def chunk_text(text, chunk_size=300, overlap=50):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(words):\n",
    "        end = start + chunk_size\n",
    "        chunk = \" \".join(words[start:end])\n",
    "        chunks.append(chunk)\n",
    "        start += chunk_size - overlap\n",
    "    return chunks\n",
    "\n",
    "chunks = chunk_text(text_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jx_EPoeLbCnB"
   },
   "outputs": [],
   "source": [
    "MAX_BYTES = 4 * 1024 * 1024  # 4MB\n",
    "def split_payload(payload_list, encoder_fn):\n",
    "    current_batch = []\n",
    "    current_size = 0\n",
    "    for item in payload_list:\n",
    "        encoded = encoder_fn(item)  # e.g., JSON-encoded string or vector\n",
    "        size = len(encoded.encode(\"utf-8\"))\n",
    "        if current_size + size > MAX_BYTES:\n",
    "            yield current_batch\n",
    "            current_batch = [item]\n",
    "            current_size = size\n",
    "        else:\n",
    "            current_batch.append(item)\n",
    "            current_size += size\n",
    "    if current_batch:\n",
    "        yield current_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3y_9lhsmKhdJ"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pinecone\n",
    "\n",
    "# Chunk text (assuming this is already done and stored in 'chunks')\n",
    "# chunks = chunk_text(text_output)\n",
    "\n",
    "# Load SentenceTransformer model\n",
    "embedder = SentenceTransformer(\"BAAI/bge-large-en\", device='cuda')\n",
    "\n",
    "#  Ensure chunks is a list of strings\n",
    "texts = [chunk['text'] if isinstance(chunk, dict) else chunk for chunk in chunks]\n",
    "\n",
    "# Embed the chunks\n",
    "embeddings = embedder.encode(texts, show_progress_bar=True, batch_size=16)\n",
    "\n",
    "# Initialize Pinecone client\n",
    "pc = Pinecone(api_key=\"pcsk_4Xke5d_QK4YNgeake3By84gyFxiRRVZP2vk7riRL5jXciZH47RtoYJep584XqaFCJaFoBZ\", environment=\"us-east-1\")\n",
    "\n",
    "\n",
    "# Connect to index\n",
    "index = pc.Index(\"medicalbooks\")\n",
    "\n",
    "# Prepare vectors for upsert\n",
    "vectors = [\n",
    "    (f\"chunk-{i}\", embeddings[i].tolist(), {\"text\": texts[i]})\n",
    "    for i in range(len(texts))\n",
    "]\n",
    "\n",
    "# Batch upsert (recommended by Pinecone to avoid size limit errors)\n",
    "batch_size = 100\n",
    "for i in range(0, len(vectors), batch_size):\n",
    "    batch = vectors[i:i + batch_size]\n",
    "    index.upsert(vectors=batch)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "173hKoJhu5BC"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "# Enable text wrapping in all outputs\n",
    "display(HTML('''\n",
    "<style>\n",
    ".output pre {\n",
    "    white-space: pre-wrap;   /* Wrap long lines */\n",
    "    word-wrap: break-word;   /* Break very long words if needed */\n",
    "}\n",
    "</style>\n",
    "'''))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OhyjMEhEH4OD"
   },
   "source": [
    "### To test run the following and change the question in the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "td_VT8HjIKAz",
    "outputId": "60a39fc9-f9db-4c3a-e61d-f2355df5c8d2"
   },
   "outputs": [],
   "source": [
    "!pip install pinecone transformers sentence-transformers -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473,
     "referenced_widgets": [
      "fbaf7291391b415c8713be400ce0f20e",
      "678075aef2734dc189f47abc497124ec",
      "347736a0d86442d8b1fd0ecdf72ff76c",
      "e2ea0af3367f4a3cb9c8bd6b6440811b",
      "b0000c38fece45ff85d1e037052f4ce5",
      "7fd2de77fea64464909b37825627e295",
      "eb18d4787cd7446b9ac83e67f52cb300",
      "53c338b2540f4c3aade1a918dfd99b0f",
      "1a2e4c7849cf4afea85ced5151c29379",
      "55fef347fb2f44ccbfdca403cb493fc1",
      "5ba4b17c84084f78ab2af76ef53a5164",
      "3c9d24f179564e8fbd17211099a7dd84",
      "241e0b1c03944d4db12817a0e8951f2f",
      "dbb71ca8b57446adb96b45e5e1b6d760",
      "f0af4dbf969641418e326a133942ddff",
      "901b72070f034fcba65c99f404b680aa",
      "7ac84c7edd5f4946830c849f81d81804",
      "db1ccbc422264c4dbe8a8d8afc8067af",
      "44acc25adc244a21a87cbc845959d80f",
      "3cacda9f358d4c6ba92233f57bc64491",
      "80fedca0e1124ad6b7662625aa5df005",
      "24fb321b6c5a4ab0a8408bc44fc03925",
      "7ab547a0d11a4c1a9934439682da1cb3",
      "f769d316ac6845e5bbd8cf7beea833a7",
      "66e88c2a269d4d149dc0efa89e98f937",
      "ca5cd79500ea403396b1f356580da29a",
      "b16dd532685a4af9867ca8164da349f5",
      "6e5ecb2230a441e7a6f4528a9dca74a1",
      "9dc73610c9284b6d9e541de8d8f7e17b",
      "0836a6af94d04692b741e06849e46c11",
      "48a2158fc2c644b9babd30fc47d53d59",
      "c0dd8ef556a34668aa0d10633943226b",
      "3d93dbafb3204d70a7dbd83b396e39c1",
      "35fa0f2e85054788a4a28d241da5a4c0",
      "555816b399c44a1099093b5e35e4dd57",
      "44e6480229c94b9da221cef71474de32",
      "446b9e12ee6f4bf9b5ad1e855212348e",
      "5553020cce2742ddb3f33c666469c242",
      "d792adcda7194764958fa80a6bb57b9e",
      "0863ce8068f5499ea5d8743665a12ff3",
      "15e7e54e7d454a218ff3264051405a4b",
      "b56141567c6c48f1bb4e347048b6eaea",
      "1908f89b616c47f48552b115714a7483",
      "00aac3338b574c13bd5b508cceca2fd6",
      "2a3930b8c42a42928144656abeed495b",
      "82b35ba47034405797424adfa910c369",
      "3d59d64103bb4f70a1728d42337d6348",
      "d9db42a565504979b8d86f498f4d187a",
      "34405c30005c4ecfbc8e84ed1be4cb99",
      "a4593e44f8644fa790fe664a733f91fe",
      "9f3663c19a7e4d35943b24992d623eef",
      "d87ab63e118a4af6ae5c6d890263f7fd",
      "fa75e811b460425e9d095ec0cfc28e48",
      "38be140a2c6a4085bdb1b3380840d991",
      "3b12dfb6dbef4c549944e145f19fb708",
      "1931e638ff664bc6b0dffee1a672e984",
      "baf7c894c8b14d11b43e03d456c0f562",
      "edccc901b75a486986dca6da881a69bd",
      "92769344006f435fbeac2d968de6bd8e",
      "e6b9bc8f702a4de1b2322917051cad7f",
      "90b26de1b98c4b19ba5b6edc23ba02ba",
      "1136d1d653414fe892b36ab9c6db8c4f",
      "838d82f559934eabbc0c6846e973a280",
      "139931d9b2ec4e1b9985fb5601ade19b",
      "e9d9b65954f94c0980a3c1ea75da30a9",
      "71f5605892b84f98a39cfa0ba718a1cf",
      "67353131dd3e41bbbcdfa4df91a11071",
      "e8ead1deec0e45da8cae346c485343ac",
      "76eec985fcf34b458582d7382418a897",
      "a140077f04d846eb9e2e9ec59dad51b7",
      "5bc904527c3d4cedbc7f8038bb93f650",
      "252d3bcd42994e0698f3a1d858cdbf14",
      "300296bd65b24244935b760c25eea7ed",
      "7f995a2a7bbd494eb78edae05214b9cb",
      "e78e6c7d1022499e885e531f3d963fda",
      "ddae82ec0aa046aeb6fd202ed2eeab09",
      "4c192833cb0149b78aa508d7df023217",
      "cf497b1c3223481cadd4554e930fa960",
      "21b15d40c45b45b5b95fe18e892597ae",
      "9de1d25529064bf684036021953a23a4",
      "570a455b32de4743a009f153d3f0b05a",
      "1c1ad4269d1f4e17aa9dbc5d459da3af",
      "8409d54f59b9410bbc1f0a473bf9e0ec",
      "0a3e115bda3d4984b6b30f6b03a4cf38",
      "13752a8fd1f74a589936d3df519c5ba5",
      "aa9ba516f0b449db94aaccacc3ff2645",
      "dcaf113264744b5aa41973eb4cde9ae2",
      "7ad9780a82704abf9c4ebfee515ef000",
      "1995622b9e694673b80b0a5baddc7a76",
      "a10cbe36dd454e9b9301cfe9362d3506",
      "ff0ff7ea16fa43de9833d40876dea2be",
      "61ba9bb2e80e45e8a656a43a4930e663",
      "a99ba64c5a1c4f029d2acf10073a9d03",
      "28abe6e9e64444f2b521b50e32f681f8",
      "becd27e86ef54d9cabe7467402a97559",
      "2138550c46ca42a0b2c2b28e135f6323",
      "24d8cb97e64b42ae95d8142537e27d90",
      "25d6c5bbc7584d748c36f0d601ba870b",
      "d6b70197a27441a8b6cfed896d88e4a6",
      "44c52ae4f761494baac0221d7e85e9f2",
      "a1c5a7cc17f747558475d9360c26c00e",
      "56dfa1fc7d514fcc938690c3109b7308",
      "f8ec29822f2d4000a2804ec50a907920",
      "bd66fef8a2c34a188eb25e61ace53f6f",
      "bff8c2af9f784e1e832052303112aa02",
      "fda1e6b8b03641d3a492c372561ce15c",
      "901d248c73dc4033ad1b05949aa0f99f",
      "011115c6181a4e859c9365e8e8efeea8",
      "051e796ca53b422585fe326ff97ff313",
      "3c3fcff391ca4e0cbec536136ec4f456",
      "31ffe4910fea4373a7c22a761a863b40",
      "32bb4a802298431494daac04202aeb87",
      "7de031e94f714a1b8cf3b6c4c41f4369",
      "94cbe2b9a7c04de9b2d1276b4ccfd468",
      "10fee66ce3754225837e28ce188d2efd",
      "d6a9cdcb4cca47cbb9dbc76acd58758b",
      "c3ad874d2e094b938b7c614d5194f38d",
      "af8459a0d1924a3ca345f46effb6d22b",
      "04f4f60033bf48ce95b33e9ec81633b9",
      "073c0b35bc924d25ac14d0b2eaf6e0e1",
      "8263c3abd997469daf7a7ccc2a6e5106"
     ]
    },
    "id": "X80mDHBvzylG",
    "outputId": "913d2476-e45a-4dbe-b679-5dd469c4787d"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "embedder = SentenceTransformer(\"BAAI/bge-large-en\", device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AzNkc04yz-0b"
   },
   "outputs": [],
   "source": [
    "import pinecone\n",
    "pc = pinecone.Pinecone(api_key=\"pcsk_5w8bJf_Umqqm1NKSfDcmrSdSApd2qyoNmSGQQXt34XKFYqQBJNnNWDbD2VT8gc19kwK53c\", environment=\"us-east-1\")\n",
    "index = pc.Index(\"medicalbooks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6nHBqN2WQGSa"
   },
   "outputs": [],
   "source": [
    "def retrieve_context(query, top_k=10):\n",
    "    query_vec = embedder.encode([query])[0].tolist()\n",
    "    results = index.query(vector=query_vec, top_k=top_k, include_metadata=True)\n",
    "    return [match[\"metadata\"][\"text\"] for match in results[\"matches\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D5KqIsKkQF_Z"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"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\",\n",
    "    base_url=\"https://api.groq.com/openai/v1\"\n",
    ")\n",
    "\n",
    "\n",
    "def generate_rag_response(user_query):\n",
    "    context_chunks = retrieve_context(user_query)\n",
    "    context = \"\\n\".join(context_chunks)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a medical assistant RAG system. You must reason step-by-step.\n",
    "Provide your response in this format:\n",
    "\n",
    "THOUGHT: <detailed reasoning>\n",
    "FINAL ANSWER: <concise answer to the user>\n",
    "\n",
    "Use ONLY the context below:\n",
    "{context}\n",
    "\n",
    "User Question: {user_query}\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-r1-distill-llama-70b\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.7\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "54UwtWY-QbZp",
    "outputId": "196d13fb-4173-4236-9abf-6db972f2c7c0"
   },
   "outputs": [],
   "source": [
    "question = \"what percentage of patients with T2DM will eventually die from CV complications?\"\n",
    "response = generate_rag_response(question)\n",
    "print(\"Bot:\", response)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
